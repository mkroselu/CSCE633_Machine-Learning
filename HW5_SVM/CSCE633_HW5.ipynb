{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44d190d",
   "metadata": {},
   "source": [
    "# HW5 - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad674e",
   "metadata": {},
   "source": [
    "## (a) Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2cd01",
   "metadata": {},
   "source": [
    "Pre-process the data via removing the headers of each document (e.g., lines that start with `From:` and `Subject:`), eliminating any additional handles and URLs, and converting all words to lower-case. Note: You can use the nltk library from here: https://www.nltk.org/ to remove stop words. Regular expression may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b800d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779986f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\MEI-KUEI\n",
      "[nltk_data]     LU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\MEI-KUEI\n",
      "[nltk_data]     LU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load stop words\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove headers\n",
    "    text = re.sub(r'^From:.*\\n', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'^Subject:.*\\n', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove additional handles and URLs\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove stop words\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw = [token for token in text_tokens if not token in stop_words]\n",
    "    filtered_text = ' '.join(tokens_without_sw)\n",
    "    \n",
    "    # Split the data based on the \"newsgroup :\" pattern\n",
    "    documents = re.split(r'newsgroup : ', filtered_text, flags=re.MULTILINE)[1:]\n",
    "    \n",
    "    # Remove any leading or trailing white space from each document\n",
    "    documents = [doc.strip() for doc in documents]\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318f9c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "\n",
    "with open('rec.autos.txt', errors='surrogateescape') as f:\n",
    "    text = f.read()\n",
    "auto = preprocess(text)\n",
    "\n",
    "with open('sci.space.txt', errors='surrogateescape') as f:\n",
    "    text = f.read()\n",
    "space = preprocess(text)\n",
    "\n",
    "with open('sci.med.txt', errors='surrogateescape') as f:\n",
    "    text = f.read()\n",
    "med = preprocess(text)\n",
    "\n",
    "with open('comp.sys.mac.hardware.txt', errors='surrogateescape') as f:\n",
    "    text = f.read()\n",
    "hardware = preprocess(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29056d6",
   "metadata": {},
   "source": [
    "## (b) Feature extraction via bag-of-words representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa53119",
   "metadata": {},
   "source": [
    "Extract the term frequency-inverse document frequency (TF-IDF) for every document. TF-IDF evaluates the relevance of a word is to a given document in a collection of documents. It is computed via multiplying the number of occurrences of a word in a document and the inverse document frequency of the word across a set of documents. Note: You can use sklearn.feature_extraction.text.TfidfVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13ddbb",
   "metadata": {},
   "source": [
    "Top 25 words in transportation document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff76f363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TF-IDF\n",
      "profit       0.411988\n",
      "saturn       0.377378\n",
      "dealer       0.334974\n",
      "money        0.240662\n",
      "reducing     0.185197\n",
      "saving       0.172601\n",
      "2k           0.157370\n",
      "1000         0.145586\n",
      "car          0.124895\n",
      "expenses     0.123465\n",
      "minimize     0.123465\n",
      "competitors  0.123465\n",
      "fred         0.104913\n",
      "of           0.103054\n",
      "pocket       0.103054\n",
      "priced       0.103054\n",
      "reduce       0.099815\n",
      "believe      0.098875\n",
      "out          0.097057\n",
      "average      0.091553\n",
      "save         0.091553\n",
      "would        0.087814\n",
      "price        0.087041\n",
      "class        0.084502\n",
      "prices       0.083862\n"
     ]
    }
   ],
   "source": [
    "tfIdfVectorizer = TfidfVectorizer(use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(auto)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f130f",
   "metadata": {},
   "source": [
    "Top 25 words in space document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b7cf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                TF-IDF\n",
      "existence     0.308429\n",
      "curved        0.271126\n",
      "dong          0.271126\n",
      "bruce         0.201005\n",
      "undefined     0.197374\n",
      "unobservable  0.197374\n",
      "observable    0.197374\n",
      "synonymous    0.197374\n",
      "tesla         0.175075\n",
      "physics       0.171151\n",
      "properties    0.159618\n",
      "theory        0.127572\n",
      "matter        0.117246\n",
      "tom           0.112934\n",
      "59497         0.105910\n",
      "unless        0.104162\n",
      "randale       0.098687\n",
      "filling       0.098687\n",
      "knell         0.098687\n",
      "refuse        0.098687\n",
      "bass          0.098687\n",
      "constructs    0.098687\n",
      "inferred      0.098687\n",
      "crb           0.098687\n",
      "curvature     0.093929\n"
     ]
    }
   ],
   "source": [
    "tfIdfVectorizer = TfidfVectorizer(use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(space)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671ba78",
   "metadata": {},
   "source": [
    "Top 25 words in medicine document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c88c33e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    TF-IDF\n",
      "gaucher           0.451486\n",
      "disease           0.263857\n",
      "genzyme           0.225743\n",
      "ceredase          0.225743\n",
      "costs             0.150072\n",
      "macrophages       0.112872\n",
      "brittle           0.112872\n",
      "enyzme            0.112872\n",
      "380               0.112872\n",
      "hieght            0.112872\n",
      "57110             0.112872\n",
      "osteopporosis     0.112872\n",
      "justifyably       0.112872\n",
      "biotech           0.112872\n",
      "biggy             0.112872\n",
      "glucocerebroside  0.112872\n",
      "netlanders        0.112872\n",
      "mutation          0.105179\n",
      "remarkable        0.105179\n",
      "relying           0.105179\n",
      "replacement       0.105179\n",
      "spleen            0.100111\n",
      "yr                0.100111\n",
      "enlarged          0.096326\n",
      "researched        0.096326\n"
     ]
    }
   ],
   "source": [
    "tfIdfVectorizer = TfidfVectorizer(use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(med)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3e2fd3",
   "metadata": {},
   "source": [
    "Top 25 words in hardware document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0786264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TF-IDF\n",
      "regions     0.384205\n",
      "nutek       0.292488\n",
      "structure   0.281377\n",
      "patent      0.247461\n",
      "region      0.230523\n",
      "patents     0.230523\n",
      "apple       0.199586\n",
      "clone       0.198840\n",
      "mapinfo     0.164974\n",
      "data        0.157289\n",
      "pict        0.153682\n",
      "stored      0.140689\n",
      "internal    0.117967\n",
      "adb         0.103229\n",
      "files       0.100675\n",
      "opinions    0.094417\n",
      "believe     0.084370\n",
      "vice        0.082487\n",
      "implement   0.082487\n",
      "engineered  0.082487\n",
      "alverson    0.082487\n",
      "50418       0.082487\n",
      "patented    0.082487\n",
      "versa       0.082487\n",
      "dunno       0.082487\n"
     ]
    }
   ],
   "source": [
    "tfIdfVectorizer = TfidfVectorizer(use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(hardware)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd89b87d",
   "metadata": {},
   "source": [
    "## (c) Feature extraction via word2vec representation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4cd01e",
   "metadata": {},
   "source": [
    "Extract the word2vec representation for each document. Word2vec leverages a neural network and a large language corpus to output a vector representation of a document via learning word similarities and capturing the contextual meaning of the words. Note: You can use the word2vec model from the Genism library from here: https://pypi.org/project/gensim/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75fd3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = auto + space + med + hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62bb9efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Word2Vec model on your corpus of documents\n",
    "model = Word2Vec(all_docs, vector_size=300, window=5, min_count=5, workers=4)\n",
    "\n",
    "# Obtain the Word2Vec representation for each document in your corpus\n",
    "doc_vectors = []\n",
    "for doc in all_docs:\n",
    "    words = doc.split()\n",
    "    vectors = [model.wv.get_vector(word) for word in words if word in model.wv.key_to_index]\n",
    "    if vectors:\n",
    "        doc_vector = sum(vectors) / len(vectors)\n",
    "    else:\n",
    "        doc_vector = [0] * 300  # if no words in vocab, use zero vector\n",
    "    doc_vectors.append(doc_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f1a72e",
   "metadata": {},
   "source": [
    "## (d) Document classification with SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214225b",
   "metadata": {},
   "source": [
    "Use a SVM to classify a document among the four considered topics using: (1) the TF-IDF features; and (2) the word2vec features.\n",
    "Randomly split the data into a training (80%), validation (10%), and testing (10%) set. Using the training and the validation sets, experiment with different values of misclassifjication cost C via hyper-parameter tuning. After finding the misclassification cost C that provides the best accuracy on the validation set for each type of feature, report the accuracy of that model on the test set. Also present the confusion matrix on the test set. Compare and contrast the results with the two types of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4329628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980 1974 1984 1922\n"
     ]
    }
   ],
   "source": [
    "print(len(auto), len(space), len(med), len(hardware))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d58cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0] * 1980 + [1] * 1974 + [2] * 1984 + [3] * 1922\n",
    "tfidf = tfIdfVectorizer.fit_transform(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0677f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec.autos document_id : 101551 article ( fred ...</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 16702)\\t0.04165758478647919\\n  (0, 85)\\t...</td>\n",
       "      <td>[0.0876568, 0.11373603, -0.037397083, -0.15062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec.autos document_id : 101552 article ( gary ...</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 37747)\\t0.1357359477746361\\n  (0, 16826)...</td>\n",
       "      <td>[-0.10963901, 0.28646937, 0.01883296, -0.02246...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rec.autos document_id : 101553 thanks responde...</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 36958)\\t0.21527382825484603\\n  (0, 26831...</td>\n",
       "      <td>[-0.36591262, 0.13937807, 0.19431634, -0.50086...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rec.autos document_id : 101554 subject says . ...</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 22975)\\t0.15565840000429534\\n  (0, 20531...</td>\n",
       "      <td>[-0.117455155, 0.28166255, 0.24468397, -0.0938...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rec.autos document_id : 101555 ( stephen wolfs...</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 10313)\\t0.048182498373623046\\n  (0, 1132...</td>\n",
       "      <td>[-0.10389984, 0.24735743, 0.06250552, -0.04224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7855</th>\n",
       "      <td>comp.sys.mac.hardware document_id : 52442 frie...</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 251)\\t0.15383515462477623\\n  (0, 20432)\\...</td>\n",
       "      <td>[0.022504378, 0.16801114, 0.25965986, -0.00103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7856</th>\n",
       "      <td>comp.sys.mac.hardware document_id : 52443 ( ja...</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 16404)\\t0.12497859358476575\\n  (0, 4390)...</td>\n",
       "      <td>[0.0038019875, 0.27972633, -0.03631023, 0.0186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7857</th>\n",
       "      <td>comp.sys.mac.hardware document_id : 52444 'm t...</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 4391)\\t0.3357299259522026\\n  (0, 37428)\\...</td>\n",
       "      <td>[-0.084446, 0.20517752, 0.29311243, -0.1522957...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7858</th>\n",
       "      <td>comp.sys.mac.hardware document_id : 52445 nort...</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 12546)\\t0.19579946671388337\\n  (0, 27401...</td>\n",
       "      <td>[0.64342797, -0.06546467, 0.6932751, 0.6785109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7859</th>\n",
       "      <td>comp.sys.mac.hardware document_id : 52446 ques...</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 36247)\\t0.11441031173412056\\n  (0, 24146...</td>\n",
       "      <td>[-0.031914517, 0.2543327, 0.31849527, 0.119638...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7860 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label  \\\n",
       "0     rec.autos document_id : 101551 article ( fred ...      0   \n",
       "1     rec.autos document_id : 101552 article ( gary ...      0   \n",
       "2     rec.autos document_id : 101553 thanks responde...      0   \n",
       "3     rec.autos document_id : 101554 subject says . ...      0   \n",
       "4     rec.autos document_id : 101555 ( stephen wolfs...      0   \n",
       "...                                                 ...    ...   \n",
       "7855  comp.sys.mac.hardware document_id : 52442 frie...      3   \n",
       "7856  comp.sys.mac.hardware document_id : 52443 ( ja...      3   \n",
       "7857  comp.sys.mac.hardware document_id : 52444 'm t...      3   \n",
       "7858  comp.sys.mac.hardware document_id : 52445 nort...      3   \n",
       "7859  comp.sys.mac.hardware document_id : 52446 ques...      3   \n",
       "\n",
       "                                                 TF-IDF  \\\n",
       "0       (0, 16702)\\t0.04165758478647919\\n  (0, 85)\\t...   \n",
       "1       (0, 37747)\\t0.1357359477746361\\n  (0, 16826)...   \n",
       "2       (0, 36958)\\t0.21527382825484603\\n  (0, 26831...   \n",
       "3       (0, 22975)\\t0.15565840000429534\\n  (0, 20531...   \n",
       "4       (0, 10313)\\t0.048182498373623046\\n  (0, 1132...   \n",
       "...                                                 ...   \n",
       "7855    (0, 251)\\t0.15383515462477623\\n  (0, 20432)\\...   \n",
       "7856    (0, 16404)\\t0.12497859358476575\\n  (0, 4390)...   \n",
       "7857    (0, 4391)\\t0.3357299259522026\\n  (0, 37428)\\...   \n",
       "7858    (0, 12546)\\t0.19579946671388337\\n  (0, 27401...   \n",
       "7859    (0, 36247)\\t0.11441031173412056\\n  (0, 24146...   \n",
       "\n",
       "                                               word2vec  \n",
       "0     [0.0876568, 0.11373603, -0.037397083, -0.15062...  \n",
       "1     [-0.10963901, 0.28646937, 0.01883296, -0.02246...  \n",
       "2     [-0.36591262, 0.13937807, 0.19431634, -0.50086...  \n",
       "3     [-0.117455155, 0.28166255, 0.24468397, -0.0938...  \n",
       "4     [-0.10389984, 0.24735743, 0.06250552, -0.04224...  \n",
       "...                                                 ...  \n",
       "7855  [0.022504378, 0.16801114, 0.25965986, -0.00103...  \n",
       "7856  [0.0038019875, 0.27972633, -0.03631023, 0.0186...  \n",
       "7857  [-0.084446, 0.20517752, 0.29311243, -0.1522957...  \n",
       "7858  [0.64342797, -0.06546467, 0.6932751, 0.6785109...  \n",
       "7859  [-0.031914517, 0.2543327, 0.31849527, 0.119638...  \n",
       "\n",
       "[7860 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(all_docs, labels, tfidf, doc_vectors)), columns =['Text', 'Label', 'TF-IDF', 'word2vec']) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff34130",
   "metadata": {},
   "source": [
    "Train with TF-IDF feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecb4766b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6288, 41870)\n",
      "(6288,)\n",
      "(786, 41870)\n",
      "(786,)\n",
      "(786, 41870)\n",
      "(786,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(tfidf, labels, train_size=0.8)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "print(X_train.shape), print(np.array(y_train).shape)\n",
    "print(X_valid.shape), print(np.array(y_valid).shape)\n",
    "print(X_test.shape), print(np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b00f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of C values to try\n",
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Train and evaluate the model for each value of C\n",
    "best_accuracy = 0\n",
    "best_c = None\n",
    "\n",
    "for c in c_values:\n",
    "    # Train the SVM classifier with the current value of C\n",
    "    clf = SVC(C=c)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the validation set and record its accuracy\n",
    "    accuracy = clf.score(X_valid, y_valid)\n",
    "\n",
    "    # Update the best accuracy and best C if the current model is better\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_c = c\n",
    "\n",
    "# Train the final model with the selected value of C\n",
    "final_clf = SVC(C = best_c)\n",
    "final_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "test_accuracy = final_clf.score(X_test, y_test)\n",
    "y_pred = final_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ba9fbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value: 1\n",
      "Validation accuracy: 1.000\n",
      "Test accuracy: 0.999\n",
      "Confusion matrix on the test set:\n",
      "[[196   0   0   0]\n",
      " [  0 206   0   0]\n",
      " [  0   1 216   0]\n",
      " [  0   0   0 167]]\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print('Best C value: {}'.format(best_c))\n",
    "print('Validation accuracy: {:.3f}'.format(best_accuracy))\n",
    "print('Test accuracy: {:.3f}'.format(test_accuracy))\n",
    "print('Confusion matrix on the test set:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d5712c",
   "metadata": {},
   "source": [
    "Train with word2vec feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baef43a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6288, 300)\n",
      "(6288,)\n",
      "(786, 300)\n",
      "(786,)\n",
      "(786, 300)\n",
      "(786,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(doc_vectors, labels, train_size=0.8)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "print(np.array(X_train).shape), print(np.array(y_train).shape)\n",
    "print(np.array(X_valid).shape), print(np.array(y_valid).shape)\n",
    "print(np.array(X_test).shape), print(np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0b73600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of C values to try\n",
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Train and evaluate the model for each value of C\n",
    "best_accuracy = 0\n",
    "best_c = None\n",
    "\n",
    "for c in c_values:\n",
    "    # Train the SVM classifier with the current value of C\n",
    "    clf = SVC(C=c)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the validation set and record its accuracy\n",
    "    accuracy = clf.score(X_valid, y_valid)\n",
    "\n",
    "    # Update the best accuracy and best C if the current model is better\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_c = c\n",
    "\n",
    "# Train the final model with the selected value of C\n",
    "final_clf = SVC(C = best_c)\n",
    "final_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "test_accuracy = final_clf.score(X_test, y_test)\n",
    "y_pred = final_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "843e1880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value: 100\n",
      "Validation accuracy: 0.562\n",
      "Test accuracy: 0.555\n",
      "Confusion matrix on the test set:\n",
      "[[121  24  34  31]\n",
      " [ 28  95  55  14]\n",
      " [ 27  31 109  21]\n",
      " [ 26  23  36 111]]\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print('Best C value: {}'.format(best_c))\n",
    "print('Validation accuracy: {:.3f}'.format(best_accuracy))\n",
    "print('Test accuracy: {:.3f}'.format(test_accuracy))\n",
    "print('Confusion matrix on the test set:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e0f438",
   "metadata": {},
   "source": [
    "**Ans**: The misclassification cost **C** providing the best accuracy on the validation set for TF-IDF and Word2Vec feature are 1 and 100 respectively. The **validation accuracy** for TF-IDF and Word2Vec feature are 1 and 0.562 respectively. After finding the best C, it was used in training model, tested on the test set. The **accuracy on the test set** for TF-IDF and Word2Vec feature are 0.999 and 0.555 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a98845",
   "metadata": {},
   "source": [
    "## (e) Obtaining additional insights with the SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4af39",
   "metadata": {},
   "source": [
    "For the best performing SVM (i.e., among the different C values and feature types), report the number of the training samples that were: (1) misclassified; and (2) within the margin (i.e., correctly classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09706505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified training samples:  1\n",
      "Number of training samples within margin:  6287\n"
     ]
    }
   ],
   "source": [
    "# Use the trained SVM classifier to predict the labels for the training data\n",
    "y_pred = final_clf.predict(X_train)\n",
    "\n",
    "# Compute the number of misclassified and correctly classified samples\n",
    "misclassified = (y_pred != y_train).sum()\n",
    "within_margin = 6288 - misclassified\n",
    "\n",
    "# Print the results \n",
    "print(\"Number of misclassified training samples: \", misclassified)\n",
    "print(\"Number of training samples within margin: \", within_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e181b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1580    0    0    0]\n",
      " [   0 1626    0    0]\n",
      " [   0    1 1567    0]\n",
      " [   0    0    0 1514]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fccb82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
